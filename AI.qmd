---
title: "Leveraging AI" 
#subtitle: "Lecture notes"
author: "Gilles Guillot, Data Integration Department, World Organisation for Animal Health"
date: last-modified
execute: 
  eval: true
  message: false
  warning: false
format:
  html:
    self-contained: true
    toc: true
    number-sections: true 
    toc-depth: 3
---

# Productivity tips for Rstudio

## In-line code completion with copilot

To activate Copilot support in Rstudio, 

* Go to [GitHub](https://github.com) and create an account
* From Rstudio: 
  + Tools -> Global Options -> Copilot -> sign in Github
  +  Tools -> Global Options -> Copilot -> Enable GitHub Copilot

## ChatGPT and other LLMs support for R coding

How to request help for a computer science issues: 

-   **1980**: ask you next door colleague
-   **1990** buy a subscription to the Spreadsheet Enthusiast magazine
-   **2000**: google it
-   **2010**: stackoverflow


 ![](images/clipboard-1191669850.jpeg){width="200"}


In recent years, LLMs have superseded traditional approaches for coding help:

-   **2024**: chatGPT
-   **2025**: Specialized models (enhanced *system prompt* + *fine-tuning* on domain data), e.g. [R and Rstudio Tutor](https://chatgpt.com/g/g-iedyANQtM-r-and-r-studio-tutor)

# Positron

# Prompts

## The various types of prompts

- **The platform prompt**: unchangeable, set by the model provider, and affects every conversation. You can see what these look like from Anthropic, who publishes their [core system prompts)(https://docs.anthropic.com/en/release-notes/system-prompts).

-   **The System prompt**: (aka developer prompt):  set when you create a new conversation, and affects every response. It’s used to provide additional instructions to the model, shaping its responses to your needs. It sets the behavior of the model (e.g. "You are a helpful assistant."),

-   **The User prompt**: the actual request you want the model to help you with.

OpenAI calls this the chain of command: if there are conflicts or inconsistencies in the prompts, the platform prompt overrides the system prompt, which in turn overrides the user prompt.

## General recommandations for writing prompts

-   It’s highly likely that you’ll end up writing long, possibly multi-page prompts.

-   It is a good idea to have your prompt on a git repository, so you can track changes and revert to previous versions if needed.

-   To ensure your success with this task,

    -   First, put each prompt its own, separate file.
    -   Second, write the prompts using Markdow (an markup language that’s easy to read and write). The reason to use Markdown is that it’s quite readable to LLMs (and humans), and it allows you to do things like: use headers, divide up a prompt into sections, itemised lists to enumerate multiple options.

-   Be explicit about what you want the model to do. For example, instead of saying "Explain this code," say "Explain this R code line by line, including what each function does and why it's used here."

-   Give examples

- Asking an LLM to suggest a good prompt is often a good idea.

## Anatomy of a good GPT-5 prompt (credit: [Antoine Mersch](https://www.linkedin.com/feed/update/urn:li:activity:7363889669333213184/))



* **Role**


  - Act as an expert travel guide specializing in recommending lesser-known and unique outdoor hikes located within two hours of san francisco.


* **Task**

  - Start with a concise checklist (3 to 7 points) of steps you will follow to accomplish this task, focusing on conceptual planning rather than details.

  - Identify and present the top 3 medium-length hikes (not among the most popular) located within two hours of san francisco. ensure each chosen hike offers a unique adventure through its scenery, isolation, or distinctive qualities.

  - Exclude extremely popular hikes like mount tam, golden gate park, the presidio, and other major tourist sites in the san francisco area.

* **Context**

  - Prioritize accuracy: hike names must match official listings (e.g. alltrails), and all time and distance estimates must be realistic and reliable.

  - Highlight what makes each hike exceptional in a concise summary.

* **Reasoning** 

  - Internally verify that all proposed hikes are real, lesser-known, and meet the defined parameters before responding. cross-check information (names, details) with reliable hiking sources.

  - Optimize for clarity, conciseness, and practical value.

*  **Output format**

  - Return the results in a properly formatted markdown table with these columns:


```markdown
| Hike Name    | Address     | Distance (km) | Duration (h) | Summary     |
|--------------|-------------|---------------|--------------|-------------|
| Hike 1       | [Address]   | [XX]          | [X:XX]       | [Summary]   |
| Hike 2       | [Address]   | [XX]          | [X:XX]       | [Summary]   |
| Hike 3       | [Address]   | [XX]          | [X:XX]       | [Summary]   |
```

* **Stop conditions**

  -  The task is complete when 
    + three unique, verified, and medium-length hikes (excluding overly popular options) are returned in the requested format, 
    + Validation has confirmed their full compliance with the requirements.

# Programatic & structured interactions with LLMs

## Chatbot versus programmatic interaction with LLMs

The layman approach to using LLMs is to use a chatbot interface, such as ChatGPT or Gemini. This is fine for casual use, but has several limitations:

-   Limited context window (e.g. 8k tokens for ChatGPT-4, 32k for Gemini Pro, 128k for GPT-4-turbo)
-   Limited control over the model and its parameters
-   Limited reproducibility (same prompt may yield different results) 
-   Limited integration in existing workflows (e.g. R, Python, bash)
-   Limited automation (e.g. batch processing of multiple documents)
-   Limited customization (e.g. fine-tuning, custom models)
-   Limited version control (e.g. tracking changes in prompts and outputs)
-   Cost: per token, monitoring usage
-   Vendor lock-in
-   Working with (highly) structured inputs/outputs (e.g. R, Md, JSON)
-   Working with large datasets
-   Combining multiple AI models/tools
-   Combining AI with traditional programming




## APIs

An APi is a set of rules and protocols that allow different software applications to communicate with each other.
For example, when you use a weather app on your phone, it uses an API to fetch the latest weather data from a remote server.
Most LLM providers offer APIs (Application Programming Interfaces) that allow you to interact with their models programmatically (through the use of computer programs). This gives you considerably more control and flexibility over how you use the models.




## The ellmer package

The `ellmer` package is an R package that provides a simple and consistent interface to interact with various LLMs (Large Language Models) from different providers, such as OpenAI, Anthropic, Google and others. It allows you to easily switch between different models and providers without changing your code.

An example with Google Gemini to get a recipe and get it stored in a neat qmd file.

```{r,eval=FALSE}
library(ellmer)
system_prompt = "You are chefGPT, a world class chef and culinary expert. You create delicious recipes with detailed instructions and nutritional information. You write in a clear and engaging style that is easy to follow."

user_prompt = "Create a recipe for a healthy and tasty vegan lasagna with spinach and mushrooms. Include a list of ingredients, step-by-step instructions, and nutritional information per serving. Format the recipe in markdown."

api_key = Sys.getenv("GOOGLE_GEMINI_API_KEY")

chat = chat_google_gemini(
  model = "gemini-2.5-flash",
  system_prompt = system_prompt,
  api_key = api_key)

response = chat$chat(user_prompt,
                     echo=FALSE)
cat(response)
writeLines(response, "vegan_lasagna.qmd")

library(rmarkdown)
render("./vegan_lasagna.qmd")
```




# Five practical ways to future-proof your career with AI

-   Audit your daily work: Spot repetitive tasks (emails, scheduling, reporting) and test AI tools that automate them.

-   Upskill in one AI tool: Pick what’s relevant: ChatGPT for thinking and ideation, Copilot for data analytics. This list isn't exhaustive, just an example.

-   Practice prompt writing: Get good at giving AI instructions: summarizing, creating, comparing, and drafting.

-   Show your value as an “AI integrator”: Don’t just use tools privately. Present the savings/impact to your team or manager.

-   Commit 30 minutes/week to AI learning: Subscribe to one AI newsletter or course. Small, consistent steps compound fast.



# Extra references {.unnumbered}

-   Ellmer vignette on [prompt design](https://ellmer.tidyverse.org/articles/prompt-design.html)
